import sys
import csv
import urllib2
import json

countries = [
"af",
"al",
"dz",
"as",
"ad",
"ao",
"ai",
"aq",
"ag",
"ar",
"am",
"aw",
"au",
"at",
"az",
"bs",
"bh",
"bd",
"bb",
"by",
"be",
"bz",
"bj",
"bm",
"bt",
"bo",
"ba",
"bw",
"br",
"bn",
"bg",
"bf",
"bi",
"vg",
"kh",
"cm",
"ca",
"cv",
"bq",
"ky",
"cf",
"td",
"cl",
"cn",
"co",
"km",
"cg",
"ck",
"cr",
"ci",
"hr",
"cu",
"cw",
"cy",
"cz",
"dk",
"dj",
"dm",
"do",
"cd",
"ec",
"eg",
"sv",
"gq",
"er",
"ee",
"et",
"fk",
"fo",
"fj",
"fi",
"fr",
"gf",
"pf",
"ga",
"gm",
"ge",
"de",
"gh",
"gi",
"gr",
"gl",
"gd",
"gp",
"gu",
"gt",
"gn",
"gw",
"gy",
"ht",
"hn",
"hk",
"hu",
"is",
"in",
"id",
"ir",
"iq",
"ie",
"il",
"it",
"jm",
"jp",
"jo",
"kz",
"ke",
"ki",
"kw",
"kg",
"kp",
"kr",
"la",
"lv",
"lb",
"ls",
"lr",
"ly",
"li",
"lt",
"lu",
"mo",
"mk",
"mg",
"mw",
"my",
"mv",
"ml",
"mt",
"mh",
"mq",
"mr",
"mu",
"yt",
"mx",
"fm",
"md",
"mc",
"mn",
"me",
"ms",
"ma",
"mz",
"mm",
"na",
"nr",
"np",
"nl",
"nc",
"nz",
"ni",
"ne",
"ng",
"nu",
"no",
"om",
"pk",
"pw",
"ps",
"pa",
"pg",
"py",
"pe",
"ph",
"pl",
"pt",
"pr",
"qa",
"ro",
"ru",
"rw",
"re",
"sh",
"kn",
"pm",
"vc",
"ws",
"sm",
"st",
"sa",
"sn",
"rs",
"sc",
"sl",
"sg",
"sx",
"sk",
"si",
"sb",
"so",
"za",
"es",
"lk",
"sd",
"sr",
"sz",
"se",
"ch",
"sy",
"lc",
"ss",
"tw",
"tj",
"tz",
"th",
"tl",
"tg",
"tk",
"to",
"tt",
"tn",
"tr",
"tm",
"tc",
"tv",
"ug",
"ua",
"ae",
"gb",
"us",
"uy",
"uz",
"vi",
"vu",
"ve",
"vn",
"va",
"wf",
"ye",
"zm",
"zw"]
with open('rebtel.csv', 'w') as csv_file:
    writer = csv.writer(csv_file)
    writer.writerow(['Country','Rate/min'])
    #countries = ['mx']
    for i in countries:
        i = i.upper()
        base_url = "https://www.rebtel.com/api/fastly/-/api/v1/rates/IN/en/USD/%s/" %i
        request_headers = {
            "Accept-Language": "en-US,en;q=0.5",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64; rv:40.0) Gecko/20100101 Firefox/40.0",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
            "Referer": "https://www.rebtel.com",
            "Connection": "keep-alive"}
        print "Base URL: ", base_url
        try:
            request = urllib2.Request(base_url, headers=request_headers)
            page = urllib2.urlopen(request).read()
        except Exception as e:
            print e
        soup = json.loads(page)
        data = soup['worldCredit']['breakout']
        for value in data:
            text_data = []
            country = soup["countryName"].encode("utf-8")
            breakout = value["breakout"]
            name = breakout["name"].encode("utf-8")
            rate = breakout["minuteRate"]
            rate = rate["rate"]
            text_data.append(country +" - "+ name)
            text_data.append(rate)
            #print text_data
            writer.writerow(text_data)
